# BASIC_CONCEPTION

## VLA的不同

生成式AI的出现从根本上改变了机器人智能，使人形机器人在物理世界中“感知、推理和行动”的方式取得了重大进展。这一巨大进步主要归功于决策能力方面的进步，这得益于LLM和VLM的预训练实现的泛化能力。VLA 不再依赖于传统的复杂策略（这些策略必须针对单个低级任务精心设计，才能实现细粒度的操作），而是能够结合视觉和语言知识，实现更佳的推理能力，从而实现机器人控制。

## Embodied AI

集成到物理实体（主要是机器人）中的智能系统（VLM）。
类似于人类从自身经历、周围环境和所处环境中学习的方式，Embodied AI通过与环境的互动以及对观察场景的视觉线索进行学习，从而能够有效地处理现实世界中的动态场景，这与人类大脑的工作方式相似。

## VLA当前发展

截至 2025 年 4 月，SOTA VLA采用双层专家系统，结合视觉语言模型（VLM）和diffusion decoders，例如英伟达的 Groot N1 和 FigureAI 的 Helix，或者采用类似物理智能中的 π0（Pi-Zero）的基础通用策略。

+ **系统 2（“慢思考”）**：在这里，VLM将视觉和文本作为上下文输入，以对复杂场景和中间任务进行系统决策。这指导了机器人的整体行为，因为它们对机器人的世界有着出色的了解。它们作为高级规划器，通过推理多模态输入并生成轨迹，将主要目标分解为多个中间子任务来实现。
+ **系统 1（“快思考”）**：transformer decoder或diffusion model作为低级控制和灵巧运动的动作专家。扩散模型具有丰富的图像先验，系统利用其卓越的语义场景关系，将系统 1 指导的路径或指令翻译并执行，以执行敏捷且精细的运动动作。

这两个系统共同模拟了丹尼尔·卡尼曼（Daniel Kahneman）的双重过程理论，结合了高级规划器和低级快速执行。

## 通用机器人策略（GRP）

机器人中的通用策略指的是一种单一的、统一的模型，能够解决多个下游任务或适应新任务，而无需针对特定任务进行微调。与传统策略不同，传统策略必须针对多个子任务或特定平台或硬件进行训练，通用策略正如其名，模型能够发展出新兴行为，以泛化到未见任务、新场景或任何硬件设置中。例如，RT-2、π0（Pi-Zero）和 Groot N1 等模型。这些 GRP 不仅仅局限于预编程或硬编码的指令，而是通过其“观察、理解和行动”的特性，自我探索和导航任务或问题，并设置中间目标。

## 为什么我们需要 VLA？

尽管LLM在基于文本的任务中表现出色，但它们对机器人所操作环境的物理约束的理解有限或受到限制。由于仅凭文本无法完全解释最终期望的目标，且 LLM 并不总是描述精细的低级行为，因此它们生成的子目标可能不可行。但是图像或视频可以创建精细的策略和行为。

VLM具有出色的泛化能力，因为它们是在包含图像和视频的大型多模态数据集上训练的。对于有效的机器人控制和操作而言，仅拥有 VLM 表示是不够的，动作数据也很重要。VLA 在 VLM 的基础上增加了额外的动作和观察状态标记。

> 状态：这是一个单一标记，代表机器人的观察，例如传感器值、夹持器位置和角度等。
> 动作：这个标记代表要执行的电机命令序列，以沿着轨迹进行精确控制。
> “VLA”这一术语最初是在谷歌的 RT-2 论文中提出的，该论文使用 PaLI-X 和 PaLM-E 作为骨干网络，将“像素转换为动作”。

### VLA 的类型

+ 类型 1：使用 VLM/LLM 作为高级规划器，低级控制由单独的策略处理，例如 SayCan、PaLM-E。
+ 类型 2：使用图像或视频生成模型作为高级规划器，例如伯克利的 SuSIE。
+ 类型 3：结合类型 1 和类型 2 的混合方法，用于规划中间任务。例如：HybridVLA
+ 类型 4：使用单一 VLM 进行端到端控制，包括感知、规划和控制。
+ 类型 5：使用 VLM 进行高级规划，扩散模型执行这些指令。例如：Groot N1、Octo